{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing on the Linux command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we learn how to perform simple text processing tasks by combining a set of tools available on __UNIX-like systems__ (such as Linux and Mac OS) using __pipes__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a very brief introduction to the Linux command line, including links to additional documentation, see this notebook:\n",
    "\n",
    "\n",
    "[Introduction to the Linux command line](01a_Intro_to_Linux_command_line.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the commands inside this notebook, you need to install the bash kernel for jupyter, e.g. like this:\n",
    "```\n",
    "pip install bash-kernel\n",
    "python -m bash_kernel.install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "export LC_ALL=C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the two files we are going to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER\n",
      "I\n",
      ".\n",
      "\n",
      "Down\n",
      "the\n",
      "Rabbit-Hole\n",
      "Alice\n",
      "was\n",
      "beginning\n"
     ]
    }
   ],
   "source": [
    "head data/alice_tok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "about\n",
      "above\n",
      "after\n",
      "again\n",
      "against\n",
      "ain\n",
      "all\n",
      "am\n",
      "an\n"
     ]
    }
   ],
   "source": [
    "head data/stopwords.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a **tokenized** version of the novel _Alice's Adventures in Wonderland_ and a list of English **stopwords**, words that express some grammatical function that we often want to ignore in text processing applications. For more details on this and how we got here, see this notebook:\n",
    "\n",
    "[Basics of Text Processing](01_Text_processing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grep` is the command for matching regular expressions. Let's use it to find capitalized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe symbol `|` means that the output of one command becomes the input of the next one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down\n",
      "Rabbit-Hole\n",
      "Alice\n",
      "Alice\n",
      "So\n",
      "White\n",
      "Rabbit\n",
      "There\n",
      "Alice\n",
      "Rabbit\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "grep -E '^[A-Z][a-z]+' data/alice_tok.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_You can ignore the occasional `Broken pipe` errors, it just means that a command in the pipeline was still writing output when the next one was already finished_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cat` command is often used at the beginning of a pipe, since all it does by default is send the contents of the file to the standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down\n",
      "Rabbit-Hole\n",
      "Alice\n",
      "Alice\n",
      "So\n",
      "White\n",
      "Rabbit\n",
      "There\n",
      "Alice\n",
      "Rabbit\n",
      "grep: write error: Broken pipe\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting can be implemented as a combination of sorting and aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    397 Alice\n",
      "    108 The\n",
      "     74 Queen\n",
      "     67 And\n",
      "     64 It\n",
      "     61 King\n",
      "     57 Turtle\n",
      "     56 Mock\n",
      "     55 You\n",
      "     55 Hatter\n",
      "     55 Gryphon\n",
      "     44 Rabbit\n",
      "     43 What\n",
      "     42 Duchess\n",
      "     40 She\n",
      "     40 Dormouse\n",
      "     37 But\n",
      "     33 There\n",
      "     33 Oh\n",
      "     32 March\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this for later. The `sed` command can be used for regex-based search-and-replace, here we use it to get a more convenient format. Then we sort the lines alphabetically, later we'll see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada\t1\n",
      "Adventures\t2\n",
      "Advice\t1\n",
      "After\t6\n",
      "Ah\t5\n",
      "Ahem\t1\n",
      "Alas\t1\n",
      "Alice\t397\n",
      "All\t6\n",
      "Allow\t1\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | sed 's/^ *\\([0-9]*\\) \\(.*\\)$/\\2\\t\\1/' | sort | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | sed 's/^ *\\([0-9]*\\) \\(.*\\)$/\\2\\t\\1/' | sort > data/ent_freqs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n",
      "The\n",
      "Queen\n",
      "And\n",
      "It\n",
      "King\n",
      "Turtle\n",
      "Mock\n",
      "You\n",
      "Hatter\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | head -50 | sed 's/^[ 0-9]*//' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice\n",
      "bill\n",
      "cat\n",
      "caterpillar\n",
      "come\n",
      "dinah\n",
      "dodo\n",
      "dormouse\n",
      "duchess\n",
      "gryphon\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | head -50 | sed 's/^[ 0-9]*//' | sort | tr [:upper:] [:lower:] | comm -13 data/stopwords.txt - | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find a way to get rid of the first words of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      ".\n",
      "the\n",
      "Rabbit-Hole\n",
      "Alice\n",
      "was\n",
      "beginning\n",
      "to\n",
      "get\n",
      "very\n",
      "tr: write error: Broken pipe\n",
      "tr: write error\n",
      "cut: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | sed 's/^$/@/' | tr '\\n' ' ' | sed 's/ @ /\\n/g' | cut -d' ' -f2- | tr ' ' '\\n' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice\n",
      "bill\n",
      "cat\n",
      "caterpillar\n",
      "come\n",
      "dinah\n",
      "dodo\n",
      "dormouse\n",
      "duchess\n",
      "gryphon\n",
      "hare\n",
      "hatter\n",
      "king\n",
      "majesty\n",
      "march\n",
      "mock\n",
      "mouse\n",
      "oh\n",
      "pigeon\n",
      "queen\n",
      "rabbit\n",
      "soup\n",
      "turtle\n",
      "well\n",
      "white\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | sed 's/^$/@/' | tr '\\n' ' ' | sed 's/ @ /\\n/g' | cut -d' ' -f2- | tr ' ' '\\n' | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | head -50 | sed 's/^[ 0-9]*//' | sort | tr [:upper:] [:lower:] | comm -13 data/stopwords.txt - | head -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the frequencies from the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice 397\n",
      "Queen 74\n",
      "King 61\n",
      "Turtle 57\n",
      "Mock 56\n",
      "Hatter 55\n",
      "Gryphon 55\n",
      "Rabbit 44\n",
      "Duchess 42\n",
      "Dormouse 40\n",
      "Oh 33\n",
      "March 32\n",
      "Hare 31\n",
      "Mouse 30\n",
      "Caterpillar 27\n",
      "Cat 26\n",
      "Well 23\n",
      "White 22\n",
      "Come 20\n",
      "Dinah 14\n",
      "Bill 14\n",
      "Soup 13\n",
      "Dodo 13\n",
      "Yes 12\n",
      "Majesty 12\n",
      "Pigeon 11\n"
     ]
    }
   ],
   "source": [
    "cat data/alice_tok.txt | sed 's/^$/@/' | tr '\\n' ' ' | sed 's/ @ /\\n/g' | cut -d' ' -f2- | tr ' ' '\\n' | grep -E '^[A-Z][a-z]+' | sort | uniq -c | sort -nr | head -50 | sed 's/^[ 0-9]*//' | sort | tr [:upper:] [:lower:] | comm -13 data/stopwords.txt - | sed 's/^./\\u&/' | join - data/ent_freqs.txt | sort -k2 -nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "*Ex. 1 and 2 are mandatory for the Data-oriented Programming Paradigms course.*\n",
    "\n",
    "1. (3 points) Redo all steps (starting with the preprocessing and segmenation steps in the Python notebook) on the German version of this text in `data/alice_de.txt`. There may be a few small things that you have to change. You can also choose another language, as long as you can find a plain text version online. Try [Project Gutenberg](https://www.gutenberg.org/)!\n",
    "\n",
    "1. (12 points) Redo the simple extraction of entities in this notebook, but include multi-word entities (we didn't find the Mock Turtle or the March Hare!). There may be many different ways to do this.\n",
    "\n",
    "1. (optional, for bonus points) Could you take all of this a step further and extract an English-German dictionary of names in the book? It doesn't have to be fully correct. Again there might be several different approaches!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
